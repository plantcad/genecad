# Directory variables
RAW_DIR ?= $(WORK)/data/dna/plant_caduceus_genome_annotation_task/data_share_20250326/training_data
DATA_DIR ?= $(WORK)/data/dna/plant_caduceus_genome_annotation_task/data_share_20250326
PIPE_DIR ?= $(SCRATCH)/data/dna/plant_caduceus_genome_annotation_task/pipeline
MODEL_PATH ?= kuleshov-group/compo-cad2-l24-dna-chtk-c8192-v2-b2-NpnkD-ba240000

SPECIES_IDS ?= Acomosus Acoerulea Aofficinalis Bplatyphylla Bvulgaris Cillinoinensis Athaliana Osativa
RUN_VERSION ?= v0.0
EXTRACT_DIR ?= $(PIPE_DIR)/extract/$(RUN_VERSION)
TRANSFORM_DIR ?= $(PIPE_DIR)/transform/$(RUN_VERSION)
PREP_DIR ?= $(PIPE_DIR)/prep/$(RUN_VERSION)
VALID_PROPORTION ?= .025
TRAINING_WINDOW_NUM_WORKERS ?= 16
REMOVE_INCOMPLETE_FEATURES ?= yes
TRAIN_VERSION ?= $(RUN_VERSION)

# Define all target to run the complete pipeline
.PHONY: all clean extract-gff extract-fasta filter stack labels sequences windows splits help validate-configs summarize run-training

all: $(TRANSFORM_DIR)/splits/train.zarr

# Help target
help:
	@echo "Available targets:"
	@echo "  extract-gff      - Extract GFF features from input files as Pandas/Parquet"
	@echo "  extract-fasta    - Extract and tokenize FASTA sequences as Xarray/Zarr"
	@echo "  filter           - Filter features based on a number of criteria (canonical transcripts, overlapping genes, incomplete annotations, etc.)"
	@echo "  stack            - Convert features from hierarchical gene/transcript/feature format to a long, stacked format"
	@echo "  labels           - Create labels from features"
	@echo "  sequences        - Create sequence dataset by joining labels and tokens"
	@echo "  windows          - Generate training windows from sequences"
	@echo "  splits           - Generate training and validation splits from windows"
	@echo "  validate-configs - Validate sequence IDs in GFF and FASTA files match configs"
	@echo "  summarize        - Generate summary statistics and visualizations of training data"
	@echo "  all              - Run complete pipeline"
	@echo "  clean            - Remove all generated files"
	@echo "  run-training     - Run training with specified parameters"

# Extract gff features
$(EXTRACT_DIR)/raw_features.parquet:
	@mkdir -p $(EXTRACT_DIR)
	python scripts/extract.py extract_gff_features \
	  --input-dir $(RAW_DIR)/gff \
	  --species-id $(SPECIES_IDS) \
	  --output $@

# Extract fasta sequences
$(EXTRACT_DIR)/tokens.zarr:
	@mkdir -p $(EXTRACT_DIR)
	python scripts/extract.py extract_fasta_sequences \
	  --input-dir $(RAW_DIR)/fasta \
	  --species-id $(SPECIES_IDS) \
	  --tokenizer-path $(MODEL_PATH) \
	  --output $@

# Filter gff features
$(TRANSFORM_DIR)/features.parquet $(TRANSFORM_DIR)/filters.parquet: $(EXTRACT_DIR)/raw_features.parquet
	@mkdir -p $(TRANSFORM_DIR)
	python scripts/transform.py filter_features \
	  --input $< \
	  --output-features $(TRANSFORM_DIR)/features.parquet \
	  --output-filters $(TRANSFORM_DIR)/filters.parquet \
	  --remove-incomplete-features $(REMOVE_INCOMPLETE_FEATURES)

# Stack gff features
$(TRANSFORM_DIR)/intervals.parquet: $(TRANSFORM_DIR)/features.parquet
	python scripts/transform.py stack_features \
	  --input $< \
	  --output $@

# Create labels
$(TRANSFORM_DIR)/labels.zarr: $(TRANSFORM_DIR)/intervals.parquet
	python scripts/transform.py create_labels \
	  --input-features $(TRANSFORM_DIR)/intervals.parquet \
	  --input-filters $(TRANSFORM_DIR)/filters.parquet \
	  --output $@ \
	  --remove-incomplete-features $(REMOVE_INCOMPLETE_FEATURES)

# Create sequence dataset (labels and tokens)
$(TRANSFORM_DIR)/sequences.zarr: $(TRANSFORM_DIR)/labels.zarr $(EXTRACT_DIR)/tokens.zarr
	python scripts/transform.py create_sequence_dataset \
	  --input-labels $(TRANSFORM_DIR)/labels.zarr \
	  --input-tokens $(EXTRACT_DIR)/tokens.zarr \
	  --output-path $@

# Generate training windows
$(TRANSFORM_DIR)/windows.zarr: $(TRANSFORM_DIR)/sequences.zarr
	python scripts/sample.py generate_training_windows \
	  --input $< \
	  --output $@ \
	  --num-workers $(TRAINING_WINDOW_NUM_WORKERS)

# Generate training and validation splits
$(TRANSFORM_DIR)/splits/train.zarr: $(TRANSFORM_DIR)/windows.zarr
	@mkdir -p $(TRANSFORM_DIR)/splits
	python scripts/sample.py generate_training_splits \
	  --input $< \
	  --train-output $(PREP_DIR)/splits/train.zarr \
	  --valid-output $(PREP_DIR)/splits/valid.zarr \
	  --valid-proportion $(VALID_PROPORTION)

# # Summarize training data
summarize: $(PREP_DIR)/splits/train.zarr
	python scripts/summarize.py summarize_training_dataset \
	  --input $(PREP_DIR)/splits/train.zarr
	python scripts/summarize.py summarize_training_dataset \
	  --input $(PREP_DIR)/splits/valid.zarr

# Run training
run-training:
	@mkdir -p local/logs/exec
	srun bin/tacc \
	  python scripts/sweep.py run \
	  --train-dataset $(PREP_DIR)/splits/train.zarr \
	  --val-dataset $(PREP_DIR)/splits/valid.zarr \
	  --output-dir $(PIPE_DIR)/sweep --configuration-index 13 \
	  --num-workers 16 --prefetch-factor 3 \
	  --batch-size 8 --accumulate-grad-batches 1 \
	  --train-eval-frequency 200 --val-check-interval 200 --limit-val-batches 1.0 \
	  --checkpoint-frequency 200 --log-frequency 1 --enable-visualization yes \
	  --epochs 8 --learning-rate-decay none \
	  --num-nodes $$SLURM_NNODES --strategy ddp \
	  --base-encoder-path $(MODEL_PATH) --torch-compile no \
	  --project-name pc-genome-annot --run-name sweep-$(TRAIN_VERSION) \
	  2>&1 | tee local/logs/exec/training_$(TRAIN_VERSION).log

# Clean target
clean:
	rm -rf $(EXTRACT_DIR) $(TRANSFORM_DIR) $(PREP_DIR)

extract-gff: $(EXTRACT_DIR)/raw_features.parquet
extract-fasta: $(EXTRACT_DIR)/tokens.zarr
filter: $(TRANSFORM_DIR)/features.parquet
stack: $(TRANSFORM_DIR)/intervals.parquet
labels: $(TRANSFORM_DIR)/labels.zarr
sequences: $(TRANSFORM_DIR)/sequences.zarr
windows: $(TRANSFORM_DIR)/windows.zarr
splits: $(TRANSFORM_DIR)/splits/train.zarr
validate-configs:
	python scripts/extract.py validate_configs \
	  --data-dir $(DATA_DIR)
