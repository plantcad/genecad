#!/usr/bin/env python3
"""
Example script demonstrating GeneClassifier inference pipeline.

Usage:
    python scripts/misc/inference_example.py \
        --checkpoint path/to/model.ckpt \
        --tokenizer-path tokenizer_name_or_path \
        --output /tmp/inference_results.zarr

"""

import os
import torch
import argparse
import logging
import numpy as np
import xarray as xr
from torch import Tensor
import torch.nn as nn
import torch.nn.functional as F
import lightning as L
import matplotlib.pyplot as plt
from dataclasses import dataclass, field
from typing import Literal, Optional
from transformers import AutoTokenizer, AutoConfig, AutoModel, ModernBertConfig, ModernBertModel

logger = logging.getLogger(__name__)

# ------------------------------------------------------------------------------------------------
# Schema
# ------------------------------------------------------------------------------------------------

@dataclass
class Source:
    split: str
    index: int

@dataclass
class Batch:
    logits: Tensor # (batch, sequence, num_labels)
    labels: Tensor # (batch, sequence)
    masks: Tensor  # (batch, sequence)
    index: Tensor  # (batch,)
    source: Source | None

    def name(self) -> str | None:
        if self.source is None:
            return None
        return f"{self.source.split}[{self.source.index}]"


TOKEN_ENTITY_NAMES = ['intron', 'five_prime_utr', 'cds', 'three_prime_utr']
TOKEN_SENTINEL_NAMES = ('mask', 'intergenic')
TOKEN_N_BILUO_TAGS = 4  # B, I, L, U
TOKEN_CLASS_NAMES = [
    "intergenic",
    "B-intron",
    "I-intron", 
    "L-intron",
    "U-intron",
    "B-five_prime_utr",
    "I-five_prime_utr",
    "L-five_prime_utr", 
    "U-five_prime_utr",
    "B-cds",
    "I-cds",
    "L-cds",
    "U-cds", 
    "B-three_prime_utr",
    "I-three_prime_utr",
    "L-three_prime_utr",
    "U-three_prime_utr",
]
TOKEN_CLASS_FREQUENCIES: dict[str, float] = {
    "intergenic": 7.531898e-01, # [0]
    "B-intron": 3.422340e-04, # [1]
    "I-intron": 1.071083e-01, # [2]
    "L-intron": 3.426275e-04, # [3]
    "U-intron": 2.781372e-08, # [4]
    "B-five_prime_utr": 9.035149e-05, # [5]
    "I-five_prime_utr": 1.633261e-02, # [6]
    "L-five_prime_utr": 9.067691e-05, # [7]
    "U-five_prime_utr": 2.447608e-07, # [8]
    "B-cds": 3.960827e-04, # [9]
    "I-cds": 9.466096e-02, # [10]
    "L-cds": 3.961328e-04, # [11]
    "U-cds": 2.781372e-08, # [12]
    "B-three_prime_utr": 8.391818e-05, # [13]
    "I-three_prime_utr": 2.688256e-02, # [14]
    "L-three_prime_utr": 8.319502e-05, # [15]
    "U-three_prime_utr": 2.072122e-07, # [16]
}
TOKEN_REGION_NAMES = ['transcript', 'exon', 'intron', 'five_prime_utr', 'cds', 'three_prime_utr']

# ------------------------------------------------------------------------------------------------
# Config
# ------------------------------------------------------------------------------------------------


@dataclass
class GeneClassifierConfig:
    vocab_size: int = 16
    num_labels: int = len(TOKEN_CLASS_NAMES)
    dropout: float = 0.1
    max_sequence_length: Optional[int] = None

    architecture: Literal["encoder-only", "sequence-only", "classifier-only", "all"] = "encoder-only"
    token_embedding_dim: int = 512
    head_encoder_layers: int = 4
    head_encoder_heads: int = 8
    base_encoder_dim: int = 1536
    base_encoder_path: str | None = None
    base_encoder_revision: str | None = None
    base_encoder_frozen: bool = True

    train_eval_frequency: Optional[int] = 250
    enable_visualization: bool = True
    token_entity_names: list[str] = field(default_factory=lambda: TOKEN_ENTITY_NAMES)
    token_class_names: list[str] = field(default_factory=lambda: TOKEN_CLASS_NAMES)
    token_class_frequencies: list[float] | None = field(default_factory=lambda: TOKEN_CLASS_FREQUENCIES)
    sentinel_names: tuple[str, str] = field(default_factory=lambda: TOKEN_SENTINEL_NAMES)
    interval_entity_classes: list[list[int]] = field(default_factory=lambda: [
        # Map token TOKEN_ENTITY_NAMES to TOKEN_REGION_NAMES
        [1, 2, 3, 4], # transcript
        [2, 3, 4], # exon
        [1], # intron
        [2], # five_prime_utr
        [3], # cds
        [4], # three_prime_utr
    ])
    interval_entity_names: list[str] = field(default_factory=lambda: TOKEN_REGION_NAMES)

    @property
    def hidden_size(self) -> int:
        if self.architecture in ["all"]:
            return min(self.base_encoder_dim, self.token_embedding_dim * 6)
        if self.architecture in ["classifier-only"]:
            return self.base_encoder_dim
        if self.architecture in ["sequence-only", "encoder-only"]:
            return self.token_embedding_dim
        raise ValueError(f"Invalid architecture: {self.architecture}")

    @property
    def use_base_encoder(self) -> bool:
        return self.architecture in ["all", "encoder-only", "classifier-only"]

    @property
    def use_head_encoder(self) -> bool:
        return self.architecture in ["all", "sequence-only", "encoder-only"]

    @property
    def use_token_embedding(self) -> bool:
        return self.architecture in ["all", "sequence-only"]
    
    @property
    def use_precomputed_base_encodings(self) -> bool:
        return self.use_base_encoder and self.base_encoder_path is None

    def interval_entity_name(self, entity: int) -> str:
        if 0 <= entity - 1 <= len(self.interval_entity_names) - 1:
            return self.interval_entity_names[entity - 1]
        else:
            return f"entity_{entity:02d}"

    def token_entity_names_with_background(self) -> list[str]:
        return [self.sentinel_names[1]] + self.token_entity_names
    
    def token_entity_name_map(self) -> dict[int, str]:
        return {
            **{
                i-1: self.sentinel_names[i]
                for i in range(len(self.sentinel_names))
            },
            **{
                i+1: self.token_entity_names[i]
                for i in range(len(self.token_entity_names))
            }
        }
    
    def token_label_name(self, label: int) -> str:
        if 0 <= label < len(self.token_class_names):
            return self.token_class_names[label]
        else:
            return f"token_{label:02d}"
    
def validate_config(config: GeneClassifierConfig) -> None:
    if config.max_sequence_length is None:
        raise ValueError("max_sequence_length must be set")
    if (config.num_labels - 1) % TOKEN_N_BILUO_TAGS != 0:
        raise ValueError(
            "num_labels must be one more than a multiple of 4 for one background class and 4 BILUO classes per entity (B, I, L, U); "
            f"got {config.num_labels=}"
        )
    if len(config.token_class_names) != config.num_labels:
        raise ValueError(
            "token_class_names must be the same length as num_labels; "
            f"got {len(config.token_class_names)=} and {config.num_labels=}"
        )
    if config.token_embedding_dim > config.hidden_size:
        raise ValueError(
            "token_embedding_dim must be less than or equal to hidden_size; "
            f"got {config.token_embedding_dim=} and {config.hidden_size=}"
        )
    
# ------------------------------------------------------------------------------------------------
# Model
# ------------------------------------------------------------------------------------------------

def load_base_model(path: str, revision: str | None = None, dtype=torch.bfloat16) -> AutoModel:
    logger.info(f"Loading base model from {path} ({revision=})")
    config = AutoConfig.from_pretrained(path, revision=revision, trust_remote_code=True)
    base_model = AutoModel.from_pretrained(path, config=config, revision=revision, trust_remote_code=True, dtype=dtype)
    return base_model

class MLP(nn.Module):

    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int, bias: Tensor | bool, dropout: float):
        super().__init__()
        self.Wi = nn.Linear(input_dim, hidden_dim * 2, bias=bias)
        self.act = F.gelu
        self.drop = nn.Dropout(dropout)
        self.Wo = nn.Linear(hidden_dim, output_dim, bias=bias)

    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
        input, gate = self.Wi(hidden_states).chunk(2, dim=-1)
        return self.Wo(self.drop(self.act(input) * gate))

class GeneClassifier(L.LightningModule):

    def __init__(self, config: GeneClassifierConfig, learning_rate: float = 8e-4, learning_rate_decay: str = "none", learning_rate_warmup_ratio: float = .1, torch_compile: bool = False):
        super(GeneClassifier, self).__init__()
        validate_config(config)
        self.config = config
        self.learning_rate = learning_rate
        self.learning_rate_decay = learning_rate_decay
        self.learning_rate_warmup_ratio = learning_rate_warmup_ratio
        self.torch_compile = torch_compile
        self.num_labels = config.num_labels
        self.num_core_entities = len(config.token_entity_names)
        self.num_total_entities = self.num_core_entities + 1 # Entity count w/ background
        self.criterion = torch.nn.CrossEntropyLoss()

        self.classifier = MLP(
            input_dim=self.config.hidden_size,
            hidden_dim=4*self.config.hidden_size,
            output_dim=self.num_labels,
            bias=True,
            dropout=self.config.dropout
        )

        self.head_config = None
        self.head_encoder = None
        if config.use_head_encoder:
            self.head_config = ModernBertConfig(
                vocab_size=config.vocab_size,
                hidden_size=self.config.hidden_size,
                intermediate_size=self.config.hidden_size*4,
                num_hidden_layers=config.head_encoder_layers,
                num_attention_heads=config.head_encoder_heads,
                pad_token_id=0,
                max_position_embeddings=config.max_sequence_length,
                attention_dropout=self.config.dropout,
                mlp_dropout=self.config.dropout,
            )
            self.head_encoder = ModernBertModel(self.head_config)

        self.base_encoder = None
        if config.use_base_encoder:
            # If path is not provided, base encoder embeddings will be required as inputs
            if not config.use_precomputed_base_encodings:
                self.base_encoder = load_base_model(config.base_encoder_path, revision=config.base_encoder_revision)
                if config.base_encoder_frozen:
                    self.base_encoder = self.base_encoder.eval()
                    for p in self.base_encoder.parameters():
                        p.requires_grad = False
                else:
                    self.base_encoder = self.base_encoder.train()

        self.token_embedding = None
        if config.use_token_embedding:
            # With no base encoder, expand token embedding dim to hidden size
            token_embedding_dim = config.token_embedding_dim if config.use_base_encoder else config.hidden_size
            self.token_embedding = nn.Embedding(config.vocab_size, token_embedding_dim)

        self.embedding_projection = None
        self.embedding_projection_dim = config.hidden_size - (0 if self.token_embedding is None else self.token_embedding.embedding_dim)
        if config.use_base_encoder and config.base_encoder_dim != self.embedding_projection_dim:
            # Use projection to ensure that projected base embeddings concatenated with
            # token embeddings have length equal to hidden size
            self.embedding_projection = nn.Linear(config.base_encoder_dim, self.embedding_projection_dim)

        if self.config.token_class_frequencies is not None:
            # Clip class frequencies on low side to 1:1M
            freqs = np.clip(
                np.array([
                    self.config.token_class_frequencies[c] 
                    for c in self.config.token_class_names
                ]), 
                a_min=1e-6, a_max=1
            )
            self.bias = nn.Parameter(torch.tensor(np.log10(freqs), dtype=self.dtype))
        else:
            self.bias = nn.Parameter(torch.zeros(self.num_labels))


        if self.torch_compile:
            # Avoid base model compilation due to https://github.com/pytorch/pytorch/issues/146129
            self.head_encoder = torch.compile(self.head_encoder, fullgraph=False)
            self.classifier = torch.compile(self.classifier, fullgraph=False)

        self.save_hyperparameters()

   
    def forward(self, input_ids: Tensor, inputs_embeds: Tensor | None = None) -> Tensor:
        B, S = input_ids.shape[0], input_ids.shape[1]
        assert S <= self.config.max_sequence_length
        assert inputs_embeds is None or inputs_embeds.shape == (B, S, self.config.base_encoder_dim)

        hidden_states = self._hidden_states(input_ids, inputs_embeds)

        logits = self._token_logits(hidden_states)

        return logits

    def _hidden_states(self, input_ids: Tensor, inputs_embeds: Tensor | None = None) -> Tensor:
        B, S, H = input_ids.shape[0], input_ids.shape[1], self.config.hidden_size

        # Compute token embeddings
        token_embedding = None
        if self.config.use_token_embedding:
            token_embedding = self.token_embedding(input_ids)

        # Compute base embedding
        base_embedding = None
        if self.config.use_base_encoder:
            if self.base_encoder is None and inputs_embeds is None:
                raise ValueError("inputs_embeds must be provided if use_base_encoder is True")
            if self.base_encoder is None:
                base_embedding = inputs_embeds
            else:
                base_embedding = self.base_encoder(input_ids=input_ids).last_hidden_state
            assert base_embedding.shape == (B, S, self.config.base_encoder_dim)

        # Project base embedding
        if self.embedding_projection is not None:
            base_embedding = self.embedding_projection(base_embedding)
            assert base_embedding.shape == (B, S, self.embedding_projection_dim)

        # Concatenate base and token embeddings
        hidden_states = torch.cat(tuple(e for e in [base_embedding, token_embedding] if e is not None), dim=-1)
        assert hidden_states.shape == (B, S, H)

        # Compute head encoding
        if self.config.use_head_encoder:
            hidden_states = self.head_encoder(inputs_embeds=hidden_states).last_hidden_state
            assert hidden_states.shape == (B, S, H)
        return hidden_states

    def _token_logits(self, hidden_states: Tensor) -> Tensor:
        B, S, C = hidden_states.shape[0], hidden_states.shape[1], self.num_labels
        logits = self.bias + self.classifier(hidden_states)
        assert logits.shape == (B, S, C)
        return logits

    def aggregate_logits(self, logits: Tensor) -> Tensor:
        (B, S, _), E = logits.shape, self.num_core_entities
        # Create list of slices for each group of classes to aggregate
        slices = [
            slice(0, 1), # background class
            *[slice(1 + i*TOKEN_N_BILUO_TAGS, 1 + (i+1)*TOKEN_N_BILUO_TAGS) for i in range(E)]
        ]
        # Aggregate logits for each slice
        entity_logits = []
        for s in slices:
            entity_logits.append(torch.logsumexp(logits[:, :, s], dim=2, keepdim=True))
        entity_logits = torch.cat(entity_logits, dim=2)
        assert entity_logits.shape == (B, S, E+1)
        return entity_logits

    def _prepare_batch(self, batch: dict[str, Tensor], source: Source) -> Batch:
        (B, S), C = batch["input_ids"].shape, self.num_labels

        labels = batch["tag_labels"]
        assert labels.shape == (B, S)
        assert (labels >= 0).all() and (labels < C).all()

        if source.split == "train":
            # Use masked labels for training
            masks = batch["label_mask"]
        elif source.split == "valid":
            # Use unmasked labels for validation
            masks = torch.ones_like(batch["label_mask"])
        else:
            raise ValueError(f"Invalid source split: {source.split}")
        assert masks.shape == (B, S)

        logits = self.forward(input_ids=batch["input_ids"], inputs_embeds=batch.get("inputs_embeds"))
        assert logits.shape == (B, S, C)

        index = batch["sample_index"]
        assert index.shape == (B,)

        return Batch(
            source=source,
            logits=logits,
            labels=labels,
            masks=masks,
            index=index,
        )

# ------------------------------------------------------------------------------------------------
# Inference
# ------------------------------------------------------------------------------------------------

def create_dna_sequences() -> list[str]:
    return [
        'TTCAATTTTTTTGACGGCTTTAAATTGCTTGTTCAAATCGGCACGATTTTCTTGTGCGTGATTTAGCGCCTTTTTTTTCTTCGATTCTGCGTAGGTAAATCTGTGCTGCGATTGTTGTGTTTTTTTTGGCTGTGCGTCGTGATTTGTGAGTGAATTTGTAGTTTCTCGTGATGCAGATTATCGAGGAGGAGGAGGAGGCGCGTCGGCGGCGATGCAGTGGCAGTTTCCGGCGACCAAGGTCGGCGCCGCGTCGTCGGCGTTCATGTCCTTCAGGTCGTCGGCGGCGGCGGCGAGGGAGGAGGACCCCAAGGAGGCGGCGGTGTTCGACCGCTTCTCCCTCTCCGGGTTCCGCCCGCCGCCGCGCCCGTCCCCCGGTGACGCCTTCGACGGCGCTGCCGCCATGAAGCAGGTTCGCCTCGCCTCCGACCTCCCCGTCGCCCACGTCGTGTCCCTCCCATGGTAGATTCTAACGGTCTGAGCTGTGTGCAGCGGCAGTTTGGATTCAACGGCCGGCAGCAGTACGCCGCCGCGGCGCAGCACGGCCACCGGGAGCAGGGCGTGGACTCCTACGGCGTCGCGGCGCCGCACCATTTCCCGTCGCCGTCGCCGTCGCCGCGCCACCCCGTGCCGTTCGGCCACGCGAACCCCATGCTCCGGGTTCATAGCCTCCCCAACGTCGCCGGCGGGAGCCCCTACAGGAACCAATCCTTCTCCGTCGGCAACTCGGTGGCCGGCTCCACCGTCGGCGTCTACGGCGGCCCAAGGTGGATAATCTCTACTCTGCTCTAATAGAAATCATTTCTGAATTTTGAGTGCAAAGCTAAGAAAAAAAAATGAGAAAGCATTGAGCTGACAATTGGATCGTTGACTTGCAAAAGGGACCTTCAAAATCCGAAGGTGACACAGATGACCATATTCTACGATGGATTGGTGAATGTGTTCGACAACATTCCGGTGGAGAAGGTATCGTATCTTTGCGACGCGCGAAATCTGTTTGATGTTACTTCAGTTCTTGGGGGTATGATTCCTGATTGTGTCATAACTGTGGCAGGCTCAAGAACTTATGCTTTTGGCAAGCAGGGCATCCATTCCGAGTCCACCGAGTGCAGCTCGTAAATCAGATTCGCCTATTTCCGCTGCTGCGAAACTTACAGTGCCCGAGGCTTTGCCTGCAAGGCAGATTGTAGTTCAGAAACCAGAGGCTTCTGTGCCTCTTGTATCAGGGGTTTCGAATCCGATCACCATCGTGTCGCAAGCTGTGACTCTCCCCAAGAGCTTTTCTAGCTCCAACGACTCTGCGGGGCCGAAATCTGGAGGCCTACCGTTGGCTGTTACTCCTTTGAGCCAGGCATCCCCGTCCCAGCCGATTCCAGTAGCAACCACAAATGCTTCGGCTATCATGCCAAGAGGTATATGGCTCTACCTTCATGTTGCTAGTTCTGTAATGTTTTTGGAATTCTGAATTCCCGGCGTAACTACTGTAGTGTTTCATAAGGTATTCGAGATTGATTCATGTTCTTGCTTGTTCCAGCTGTGCCTCAAGCTCGAAAAGCATCTCTCGCCCGATTCTTGGAGAAGCGAAAGGAAAGGTATAAATCGTGTCATCGTGTGTCTTGTGGTTTTACTTTGCAGCTGAAATCTGTTACTATGGTCTTGTGCATATTTTTGACATGTGCCTTGTTTATCATGTAGAGTGTCAAGTGTTGCGCCATACCCATCCTCAAAGAGTCCACTAGAGAGCAGTGACACCATTGGCAGTCCCAGCACACCGAGCAAATCATCGTGCACGGACATCACCCCTTCGACCAACAACTGCGAGGACTCACTGTGCTTAGGTCAGCCAAGGAACATCAGCTTCAGCAGCCAGGAGCCCCCCAGCACAAAGTTACAGATATGAGACCTGGTGATCATTGTATACCGAAGATTCAGCTCAGCGAGAGTCGGCTGACCTTGATGCCAGATCGGACGCCTTCTTTCGCATCCGTGTTAGGGTATGATGAGACATAGGAAGAGATCACTAGATGCTGTTTCTATCCTGGCTGCAAAATCTTTCTTTGGCTAGAGCTGTTTATAAGTGCTGATCTAGCCACAGCCGCCGCCACTTAGTAGTACGAGAGCTGTGACATTGCAGGTAATTTCAGGCTGTTCTTGATTATTTTTGCCCTGAGCCATAGCGGCATTGGACTTGAGAGGAAAAGAAATGCTGCTGAGTTGTATAGGATTACAGATTCGGCGTATGTAATTTTGCTGTTTTTTGGTTCTAGCCTTAAACATACAAAGCTAGCTTCAGAATTCAAACAGAGTATCCCTGATGCCAATATGCCATTGCCATGGCCATTTTTATATGTTCGGTACATTTGTTGTTGCATACTGTTTTGTGCATACAGGCGAGAATGCTTGTCATTGTAATGACTAGCGAGTTTTTGTAGCATGCACATCACGCAGCTAACTAAGATTATTATGCTTCCCTTGGAGATCGCATGCAGTGATATGTTACAGTGTTTACTTGATTGTAGTCTCTCCCAAGCTAGTATACTCTACGTAGTCATAAATATTGTAAAAAATGACCAAAACTTGTGCTAAATATTAATATTTAATATTTATGGCTAAAGGGCTAGGAATGAAAACGGATAGAAAAATGCTCAGACCATTTCCTTTGCTTTTTTTTTCCTTTTCGGAAACAGAACCGAACGGTAGAACAAGAAAGGATATACTGTTGAAACATTTTTTTTAAAGAAAAATATATCAGAAACATAATTATTGCTACCTCCCTCATAAAAATTAAACTTCTACCTTTGAATATTTGTCTCGTAGAAATTGTATTTCTACTCCCGTTTCATATTATAAATCATTTTGACTTTTGTCAAAGTTAAATTACTCCAAATTTAACCAAGCTTGTAGACAAATATATTAATGTTTATAGCACCAAATTAGTTTCATTATATGTAAATTTAAATATATTGTCATAATATATTTGTCTTGTGTTAAAAATGTTAATATTTTTTTCTACAAACTTAATCAAACCTAGAACAGTTTAACTTTGACCAAAGTCAAAACAATTTATAAACTGAAATGGAGGGAGTATTTAATATAGGACCCAACAAATTGATTACATCAAAATATATTTCCTTGTAATCTCTCTTCCTTCCATCCCATCTCTAACTCATTGTTTTAACCTTATTTTAATCAAGTTTATATATGAAATGTGTGCATACACTGTGTTCATTAAATGAGGTTATTATGATAATTTGTCTATTCTCCTAATGTATCCTTAGTTCCTTAGAAATTTATTTTTTACGGGACAAAAGTAGTAGAATAGAGCATTAGAAACAACGTATCGTAAGTGTAAACAAGTTGCACCCAATGTTTTGTTATAAATCAACATCATATACATCTACCATTTGAATACTTTACTAGCAATAATGTCTATGCGTTGCAACATGTAAAAACCAATTTTAAATAACTGAACAAAACTAGCCCCTTTGGTCATAAAAAAATGACGTTTAGATTAAGATTTGGTCAAACTTTTAAAATTCAAATCATTAATAGTTTCTCAAAATGAGTTTTTGAAACAAAATAATCTAAGTACTCTAAAAAAAAGTGATGGTTAGAATTTAAAAATTTTAACTAAATCTTATTGTGAATGTCAAATATTTATGACCAGATGGAGGAAAAGGTTTGCGATGCATATATAGTTGTCATTGTCTAGCTACTAATCCATCACCCACTATGGTTGATAAATTGTGATGGAATTCGTTAGTTTTGAAGTTGCAAACTGCAGTTTTCTTGTACAGTAGTGTGTGCGCACTTATGTTGACTAAAATGGCTCAGGTCATGAAGAAAATATTCCCGATACAATTATTTAGTCTATTGATATTTATGAGATTTGAGGTCAGCCTTCGTCAATAATATGAACCATCCTATGATAAAGGTGAGATACATGATAGATGGACACCGCATGAAGTATTGATGTGATGTGGTGAGCCAATGTGTATGAGGCAAGTACTGAGATTACACAATGGGAAAAGCCGAGATACATGATAGACGTGCACTGTCTAAGAGAATTAACATGACAACTGGCTGACACAAGTCGATGTGTATGATCGTCAAAAATCGCAAAAAAAAAAAGTAAGAACAATGGTAACATAAGATAAAAAGAATCCCATTTTTGAAATCACAAGGGGACACGGTACTGGTTGGCTTATTGACTTATTGTTTTACGAAAACACGGATACATTTTCTATTTACGCTATGCTAGAAACTGTCCATTTAGTTGGCTTGTGCCAAACACATCTAAATGTCAGACACTTAGAAGGCATTGTTAACAAAAATGAAAATAGTTCTTAAATCAACTCTTAGGCTGCAAATTAGAAGTTCAAGCACACATTTGTAAGGTGCAAATAACTATATCGTTTGTGTTCAAAATCCTGAATCGGAGTAAAATAACAAATGGATCAATTTGCCAGCAATCTAGGCCCATACATAACTACAAACGGACCCAATTAGGCCGCTACACTGGTAGCAGCCCAGATAAAGATGGGCCAAAGCGTTGCCATACCCAACGCGGGTGTATTGGATTGGGCCCATTGGTAGCGTTCCAATGTTGGGTTGGGCCCAATTGTCTAAAATGGGCCGACTGCTTCCTCCTTTCTCCGTCCACTCGCCGGAGTGAGTCACTCGCTCCCTCGCCCACCGCCGCCGGCGCCGCCTCCCTCCCATGCCCTCCGGCGAGCGCCGCAACCAATCCGTCCTCTGGGGTGGTGAGAGGGATTGGATGCGGCCACGCCCCACGCGGCGCGAGCAAACTCAGCAACATAGCAGCACCAGCACCAGCACCAGCACCAGCACGAAGCGAGCAAGATGGCAAGGGGAAGATGACGAAGAAGATGACCAGATCAACGGGCTCCCCGACTGCCTTGAGCTCCGGCGATCGCGCGTGCCGTCTGCGAGGCTGATGCCCCAACTCCTGTATCCATTTGTTGTGCTACTCTTTCTTCTGCTCCCGCACCTTTTTTTTTTTTTGTGTGTGATTATGATACACCTATATTTTTTTTAGATAATAAAAATGATTTACATCTTCGGCCTCTGCGAATAAGTATATGGCCAATTAGTCAAGAAAAGATAAATAAAAATACTCGAGGCTATGGGACAAATCCTCATCTCCCAACCGATGATATATCAAGCTGAAATACCGAAAGAAAACACGTAGAATCTATAACGAATGATGCACCTATATGCTATGCCTGTATTCATGTTTCTGCAGGTAATTTTTGTTTGTTAAATTCTATTTTTGTTCCTGAAGAAATCATGTGTTCTGAACTTCTGATAGGTTGCTGTTGCGAAGGTGGAGCCTGATCTCTAATACAGCATGACACTTTCTACCTTATTGCATCTCATGGATTAATTCTCACAGTGTTGGAAAGAAGGGGTTTTCATTTTCATTATTCAGTTTTATTTGCCCTGTCTTTAATCTATTTTGCTTATCTAGTTGTGCTATTTGAAAAGTATAAAGGTTGTTTGGATGTTTACTTATCAGTTGGTGGTTACAGAATAGTATATTCAGTTTTTGAGTCTGTTAGTCTCATAATTGTCTATTTATACAGGTAAAATTTGCTACTTAGAAGACATTGATGATGTTAATTTTTTAGATTATTCTTTAGAAACAACATTTATATTTATTACTCTATATTTGTGTGCACAAGGCCTAACTGTTTTATATGTATAAAGACTGAAGATAATATGGAGTTTGATATGATTGGTGTTGATGCATCGATAACTAATGCCTTATGAAGAATCCTCGTACCAGAGGTATGCGCATGTTGCCATCTGTACCATACTACCATCTTGAAAACTGTTTGTTGCGTTCTAATGAGTCATGTATTTGGTGGTTCCATTCCAATACATGTACTTCATTATTTTAAATTACAATGTTCCTACAACGGAAAATTGAGAAAGTCCTCATGGTTGACAACACATCAGTTACACCAGATGAAGTTATTCTACACAGGCTTGGTTTGATTCCACTGGATGCAAATGGATCCTTTTTATTATATCTCAGGTCAATAACTTAAAATTTTCTAATTCCACATTCATATATTTGATTGCTATGTATGAATACTTGTGTATGAATAATAGCTGTATTATTCTTTCGTTGGGTTCTGTAGAGAACGATGCCTCATTATTGTGTACAAACTGCGTGTTTCATGTTAGAAAGGCCCCCAGCTTACAGTTATCTTCGCTGTCCTGCAACCTAACCCTTTCACAGTTTCCAATCATCTTATTTCTAAGTACGAATTTCCTCCCTTCCAATTTGAATTGTGCAAAACTGCAAAAGTGATTTATTTCTAAATATTCTTCTCCAGGTTATTCTTTGGAGTCATTTTTATTCACTGCTTTTTAACTTTTAAGACTAAATGCCATGTTTTTCTCATTTTTACTAAATAAGCATCAAGTTTACAAATTTATCTTGAAATTGTGGACCTTATTTTTATGGGAGACAATTTGCACCTGCCAGCTGCAACTGGATAGATTAAACAACCTGATTTGATGCTGTTAGTGACCTTCAAACCACCATCTCCTTTAAGCGAGGATGATCCAATTATCTGTTTGAAACATCACATTCTGTGCTACGAGACTTACATAAGAAGAAAACTGTGTTATGTTTCACAAATTGTGGATCCTTAGTCTTTAGATATGCGGTTAATGGGTAAATCCCCACATTGACGACATTTCATATTATTATCTGAATATACAGCATAAATCAGCTAAGGCACCAACCTTTTCTTCCATCTTAAAAAATTCTTAATAAAAGCCAAAACTATTTGGAATCATTTAAAAATATTTTGATGCCACATCAATCAGATTTACTCTGTTCAGAATAATTTACAAAGAAAAAAGTGAGGGTAAATCCTTGGCAGCAAAGCATGTGCCTAATGCTACTATGTACCAATATAATATTTTGTGTACCAAAAACTCAAACTATCTAAACAAATTTCTTAACTGATTTTCTGATACCATCATCATTCATGCACGCTGAATCAAACAGTGGATCCTTAGTTATTGGTACTTCAGCTTATTCATGCCAATTCTGTTATCATTGTTCTACTTGGAAAGCTTTGATGGCTAGACTTCTTGTTATCTCTTCTTTTTTTTTTGCGAAGTTGTTCTCTTATGCTAATCAATCATGTAAGAAATTAAATTGCTAAAACCTAAGACTTATATCAATGATAAATTAAGTATTCTATTCTTTGTGCCCTTATCGTTATTATAATCCTGTCATATTTCCTGTAAGGTTGACTGATATTTTCTACTGAGGTGTGGTTAGCAGAAAATAGCCAATTAAATATGTCATCTCCTGCTCAATCTGGGAACAAGCAAAAGACCTACACTTCCTTCGGCCAAAGCAAGAAGGATATCTCAAAAAGGATGGTGTGAAATTTAACGATATAACTATTATGAGGTTTGGACCTGGCCAAGTAAGTTTGTTATGGTGGTTGTTATCATGGCTTTCCCCTTGACACTATATGATATACTTGGTACCTATATCTGCTGTCATTTAGGCTTACTATTTGGATTATGGCGCTTTGCTGAGTCCACATGGTATAATAAAGATTTCAACGCAGTCATTTCCTGGAATCCTGATGTATGTAGCTTTACCATTATTTTTGTGACCAATCAATTTTTTTTGCGGCTTAAATTTCTGCTGGAAACCTGAGTTCATGTGCATGCTGATAGAAATTTCTGCAAAGATATTTTCTTGTAGAGACCTGCTACTCTGAAATTGCTTTACTAATTTTTCATGGGGTAATTCTCCGCAAACCACCGTGCCTTCTAATTTGCCTAGTCGGTTCTATTTTAGGCTATTGAACTTGAGGCATATGCTGTTAAGGGAATGAGGAAAGTTCATTCTAAGTGGTCTCCAGTTGCTACTACAGCCTGGTACAGAATTTCCCTGAGGTAAAATTCTTTTGCTGGAATCTCTTATAAGAAAACCATGAGTTGCTATATACTATTGTTTTCATGGCTTAGTGTTATATTATTGTGTAGTTGTTTTTCTCAAAGAAGTAAAAATTGATGATGCAGATAGGCTAGTGAAGAAGTGCCCACTCAATATTTTTGACATTGGAGATCAGGGAAACTGCAATTTCTGTTCCCACTAGCTATGGGCGTTGTTATTTTACTAGTGTTATCTT',
        'GTGCGGTGGAGTTGGGTTCCCAACCCCAACTATCAAACACAGCCTAAGGATGAGAGTATGCAGGAAGCGAAGACATTGACATTGCTAATTTATCAAATTATTTTTTATCATGTTTATTAAATAGCTGTGAAGCAATGAGATAAGGAACGCTGCTAATAAAACCAGTTGACTTTGCACAGTACTTCTTCCGTCAAAAAATATAGACATTTTTAAGATTGACACGGATATTAATAAAGTATATGAGAATGATTGGAGAAAGTATGTGGTTGGCTGAACAGAGAAAGTGCGTAAAAAAGAATGGTTGTGATTAGTTGAGAGGATGAAGTAGGTGAAGAAATAGCTTTATTTTGGGACAAGATACTGTTTTAGAAATAACTATATTTTGAACGGAAGTAGTAGCTTGTTAGACACATTTGTTATACAAACAGTATGGAGGGTAGACTTCATTTGTTTGTATATATATATACGTTGTCAACGCATAAAAGAAACTTGAGTGTGAGTTGACCAGAGGGTCCAGAAGTACTATGTGGGATAGGCGATTGAACTTTGAAGGGGGAATAATATAAGATTAACATCTCGAGAGAATATCATCTCGTTTGTTCATACACTATTCAAATAGTTAAAAAATGACAAGATTTATACAACATTCATATACAATTTCACAAAATCTTATCTAAACTCAACTCATATATTCACATAGGGATTTGTCAATTTTTTAATTATACATTGGATTTGTCTTTGTTTTAATTATTTCTCAAAGTGTGGATCAAGTTTTAACTTACTGTGTTTCATATTATAAGACTTTCTAGTATTGTCCATATTCATATAGATGTTAATTAATCTAGACACATACTGGATATGTGTCTAGATTAATTAACATCTATATGAATGTGAGTAATGCTAGAAAGTCTTATAATATAAAACGGAGGAAGTAATAGATTTAGATTTTTGGTGCAGTGATAAATGTCACTGGATTTTTCCCTAAAACATTTTGTGATCATTTATGTTGAATTTGATTGAAAAAAGGGATATCCTTGAGAGATTAAAATCAATTCCTCTATTTAAGGTGTCCTAGAGCTCAATGTTCAAATCGGAGAAGAAAATCAGAACCATAGAATATACCTATTTCCCTGACAAGTTTTTAAAATTTAAGCGTAAAGAATGAGAGTCAAACACAAATAAAATGGGCTAACGAAATCTCGCGCAGGCACTACTATTGCCGGCCATAGCGAAAAAAATATCACGCAGGGCGGCATTATCATGCATAGCTTAATAAGAAACGAAAGAAAAAAACATATCTGTACGACCATGTGATTCCTGTTTTTTTTTCCCTCATGGCATATCTTGATTTGGAATTTTGTCATAGACTTCAGAAAAATGTTTTATCAGTACAGAATCTGGACGAGTTCTCGTAAAACTGAAATCAATACCTTAGCAATAAGATTTACTACTAACTCTGACCAGTGGTACTAAATAAGATAATCAATGCCACTTACTGTAGCTATAAAGGAGAAGGTATGTAACTGAGTGCACCCACAATAGTTATCTATAGGCTCTTTACAATAGATCCATGTCAACATATTTTCCTACTTGGAAGAGATTAAATGAAGAGAGAGAGCAAAGCTATCTACTAACCTGGAGAAAGTCTATAGAGAAAAACGAGGCAATGGATTAGAGAGCTATAGATACCCATGTAGACATACCATTGAAGTGGTTTACTATTAATCTAGTCTATTACTGAGATGTAAATGTTTTATAGATAGCAACTTACTTTACCATTGCGGGTGCTCTGAAGCCAAAAGGTACTTGTGCCAACATGTTTGTCTTGGATAAACTAAAATATGTCCTTCGAAAAGAATAAAACAAAACAATATTAAAGGTATAAGTACATCGTGTATGTTTTATATAGTAAATCTAAATAAGAGCTGTTGTTGAACGCGCAGGTACACGAATTAGCGAAAAGGAAATGGAGATAATACGCATGGGCGGCTCTGGCAGATAGATACAGCAGCAAGGACAAGAAACCAATTCAAGAAGTGTCAAAAGCAAAGTGCTGCGCCTATGCGCGCTATGAGAGGAAAAAAGGCCGGGAGCAGAGCACTCCTCGCCTATATAAAGAGAGGCTCAGGCTTCCCATCCCCTCGCGCGGCTCAGAGCACACAGCTCCACCAACCTCACACGGCCTCAGGCCTCAGCCTCCAAAGGGGAGACAGGAGAGAAAGCTAACGCTTCTCTCTCTCTCTCGGTTAATTGCCTGTCTGCGTGGGAGTTACCTCCACACAGCGCCGTAAAAGCTTCGAGCGAAACCCCACGCACGTACGCAGGCACGCACACGCGCGCCGGCGGGCGGGAGAAGACCAGAGTGTTCTTCTGTTTCAGCTATGACGACCTGCGCGGATGACCAGACGGGCTGCGCCTTCTTCGCCCCCTTGCTGTCCTCCAAGGGGGCGGAGGTCGTCATCTTGGTGGCCGGCGATGAGGCGGAGGAGCAGCAGCCGGCGCCGGTGCTGACGAGCAAGCCGCCGGGTCGGCTCGCCAAGGCGGTGAACGAAGCCTGGTCCGTTTCTTTGGGCGTCGCGTTCCCGGTGACGCCGTCCATGTTCACCTGCTCGGCACGGGGCGAGGCGCGGTCCATTCTTGGCCTCGCATTCCCGATGATACTGACGGGTTTGCTGCTCTATCTCCGGTCGATGATCTCGATGCTATTCCTTGGTCACCTCGGCGGGCTGGCCCTCGCCGGCGGGTCCCTCGCCATCGGATTCGCCAATATTACCGGCTACTCTGTCCTCTCCGGCCTCGCCATGGGCATGGAGCCGATATGCGGTCAGGCCTTCGGCGCGGGCAATTACGCGCTCCTGGGCGTCACCATGCAGCGGACGGTGCTCCTCCTCATCGCGGCCGCCATCCCCATAGGTGGCCTGTGGGTGCAGATGCGGCCTCTCCTCCTCTTCTGTGGCCAGGACGCCGCCATCGCGGCGGTCGCCGAGACCTACATTTTCGCGTCTCTCCCTGACCTCGTGCTCCAGGCATTCCTCCACCCGGTGAGGATATACCTCAGGACGCAATCCATCAACCTGCCCCTCACCGTGTGCGCCGGCCTGGCCATTGCCATCCACCTCCCCATCAACTACGTTCTCGTAGTCGTCCTCGGCCTCGGCGTAAAGGCGGTCGCATTGGCGTCCGTGCTGGCCAACTTGAACCTCGTGCTCTTCCTCCTCGCCTACATCTTCTTGAAAGGCGTCCACAAGCGCACCGGCGGTTTCCTTCTGTCCGCCGAGAGCTTCCGTGGCTGGGGCGAGCTCATCAGCCTCGCGCTGCCGAGCTGCGTGAGCGTCTGCCTCGAGTGGTGGTGGTACGAGATCATGATCCTGCTGTGCGGCCTGCTGCTGAACCCGCAGGCGACGGTGGCGTCCATGGGCATACTGATCCAGACCACGTCGCTCATATACATCTTCCCTTCGTCGCTCAGCTTCGGCGTGTCCACCCGCGTGAGCAACGAGCTAGGCGCGGGGCAGCCCGAGGAGGCGAGCCGCGCAGCCACGGTGGGGCTCGTGCTCGGCTTCGGGTTCGGCGCCTTCGCCTCCGCGTTCGCGTTCCTCGTGCGCAACGTGTGGGCGAGCATGTTCACGGCCGACCCGGCCATCGTCGCGCTCACCGCGTCCGTGCTGCCCATCCTGGGCTTGTGCGAGCTCGGCAACTGCCCGCAGACGACGGGGTGCGGGGTGCTGCGCGGCAGCGCGCGGCCCAAGGACGCCGCGAGCATCAACCTCCGCTCCTTCTACCTCGTCGGGACGCCCGTGGCGCTCGTCATGGCATTCTGGTTCCACTTGGACTTCAGGGGCCTCTGGTTCGGTCTGCTCGCTGCGCAGGCCACCTGCACGGTGCGCATGCTGCTGGTCATCGGCCGGACGGATTGGGCGGCCGAGGCCAAGCGGTCCAAGCAGCTCACCGGAGCGGGCGCCGCCAACATGGAGAGTGACGACAGAGTTGCCGCGGACGAGAAGTCGCGCTTACCCGTCGATACGGACGTGGAGCGATCGAGCGATCACACTGATCGGTGTTGAACTGCTGACAGCAACAGCGCGAGCCGCATGCGTATTGTAGTAATCTAGCCTCTCTTTTTTTCTTTTTCTTTTTTACCATTTTTATTTCCTCCCTCTTTCCAAATTTCGGCGGGGGAGGAATCAGATGCTGACAGAGCGACAATTTTGTTCTCGGATGCTAATTAGCAATGTAAAGATTATGCTGATTGTTTATTAGTAGCATAGAGTTGGAGAATATGAGATACCAAGGAAAAAGATTAATTTTGACTCTTTTCACAATGGAGGAGCAAACTGTTCACGGCTTCGCTTTCTCTTGCTCCGGGTCGGTGTCTGGTCCAGGGAGGCCGGCCGCGTGACGACTCGGTCAGCGGCACGGGCCAACCAGTGGTAGCACCGGGTCTCAGCTCTAAAGTCGCGTGGCGCGTGGCTTTGGACAAACCGTCGGGACCCGCCATTTTTTAGCCTCGTAGCCGTCGGGCCGTCAAGTTGACACTCGCGGCTTTAACTTCTGGTAGCCGGTACCTTTTCGGATACAACTGTGCTATGGAAATCGGACTATCGCACGTTCTTGTAACAAAGGGCCGGCTGACTTGTAAAGCACACCTAATTGCTATCGATTAGAATTCTAGACCATGATTAGCTCTGGTTTTCTTTGCTTTTGGGGTTAGGACCCGCATGCTTGTGTATTGAGAAAATTCTGTAGGATAAGCGTGGAATAGTCCATCCTATAAATTACAAAATGCAAACCCATGTCTCAAAGAGCTGTAGGATAAGCGTGAAATAGTCCATCCTATAAACTACAAAATGCAAAACCCATGTCTCGAAGAGCCCTGCTCCGGCCGGCATCGCGGGCAAGCGAGCCCCACGTTGAGGCGTGGTTGGGCTTGAGCGAGCTTCCCGTGCGCGCGGCTCGCGCACAGGCCTGGATCCCTGTGTTCTGGCTCAGCTCAGCACCCACGCGCGTGCGCGCGACGGATGGCGTTTGGCACCGGCATCGCCGCACCGCGCGTTAAAAAACGACCCGCTCCTCCGCTCTCGCTCGCTCAGCCCCAACTCGGCCACTCCTTTTTTTTTTTTTGGAAACCTGCCACTCCTTGGAGTTCCTAGAAGATGGCACTGTTTGGAGGCACCAAAAGGCATCGTCAAGCTGTCAGGCCTGCTTATATATGCACTGCTAGTACGGAGTACTATAAACTAGTACTCGTAATACCGAACGTTTGGATAAAGTACAGCTCATCTTCACAAAGATGTTGGAGTTCGGATCGAATGCCCGAGCTGCACAATGCGCTGCATAGATCGGAGACCGACCGATGACTAGATGAGCACCTGTTGTGCCAACGGATAACATGGTTATGTGTCTGTTGTATGTGCTCCCCGCCCAATCACACCTGCTGCTGACGTGGAAGGGAATCGTACTCATTTGGAGTCAAAACCGTTGTTTACCTCCACCGATCGAAGAATCTGAGGTGGAGTGGCAGCCTGGCTTGCTCAATCGACCAATGGGACTGTATACACGCTTGAATGCTTGATCCTTTGAGAGTCAATGATTGTTCCCGGTCGCTTGGATTGGATCATTCCAATTTAAACAAGTTATGTTCCCTGGTTCTTGGGCGAGCTCGAGAGGTGTCTCCACCGAAGTAGAAATCGCGTTTACTTTCCTACGCGATCAGCTCACGGCTCATCAGTGATCGCAATACATGCATGATGCACACGTCCCATTGGGCTGAGATCGCATTTTAATTAGGCCCCCTTTAAACTGTGACCGATAGTATAGGTCGCATGGCAAACCGTTTGAAAGGGCATGTACCTATTAAAGGCTAAGTTCCTATTAAAAAAAGCTACATATATCCAAATGGATATAGAGGCCGGGTAAAAAAATATTCTTCTAAAAAAAAGATTCAAAACAAATTTTCCAAGAGATTAAAACTCTTGCTTACTTTCCTATAAAATATCTATAGAATTATCCATTCCATAGGATTTTTAAAGGAAATGATATGATTCAATCATTTGTTTTAAAGGGTTTTGTAGAATTTTTCCTATATGATTGAAATCATTCAAATTTCCTATGTTTTTTCCCTTACAAATGAGGGTTCTTTTGAAATACGAGATTGAAAAAAAGGAGGAATTAAAATAAAGTAGGATTTTGACATGAATATAAGTGTCAAACAAATAATTACAAAACATGCAAAAAGTACAAGAATGATTGTTTGAGTTGACCGAAGAAAAAAATCACATGAAGCGGATGAGAGAGAGACTCATAGAAATTTTCAAGAGATTGTGCCCTTTGATCATATATACTATTCCTATATAATTATCTCCATTAGCTGTTATTCTAGCTAGCCATATCATCTTATTTATTTCAGCCATTAGATCACTATCAAAATCCAATAAAAAATGTTAGATCCCCTTTTCCTCTTGTCCTATGTCACTGCATGTTTGCATCTGTTTGAAACGGTAAGTAATAAGAACATCCCTAACTTAGAAACTATCAACTAGTTTCTATAGTTGCCATGTCATATAGAGACTATGTATAAAAACTATATATCAATGGACAGTGTCTTCAAATTAAATTCTCATCCAATCATCTATCCTCTCTTCTTTTATCCACATATGCCATTGTTTTCATTCTTGGTTCTTGTGTAGAGATGATTTCTTCCATGAGAAATAATTTATTCATCATTTTACATCTCTCCTCATTAACTCTCTTGCCACGTTAGATTTTTGCTCATGTGACAATTTATTTAATGCTATAGATACCAGATGATATGGAGGGCTGAGGATGGCCTAAAAACTACCATCAAAGCTCTTTTTCGCCAAATTGGCCCTAATCCCATTAATTCTCTCATAACTATCCTACAATTAGGATAATCCTCACACACAACGGCATCCTCCTTCTCGAGAGCTGATGTATGCCATCATCCCTTCTTAATCGATGCTAATTACATGGTAGTCATCGTTCATTTCCTAGAGTACTTTAGTTTTGCCGATTATCTATAGCATATATTTGCTTTCATGAACAACACTTGACAGCAACTCATTGTACATATCCACTATACCTGATATTTGCAAGGTTAATTATATCAATGACTTTTCGGTTAGGGATATGCTTATGTGAAAGTATGTTCAAATTTTGATTATTTGAAGTCGTTCTATATTCATGTAACTTTTAAGTTAAACTGAGAAAACTTCTGCACATTGGATTTTTTTTAATTTTCCCGCACATAAATGTTTATGTCTAGCTACATACACATGTAAAAGCCAAACACTTTGTGACATACTCCTTTCATCCCATAAAAAATTAATCTAGTACTAGATGTGACATATCCTAGTCTTACGAATCTAAACATACCTTTATCCAGATTCATTGTGCTAGAATATGTCACATCCAGTATTAGATTCGTTTTTTTTGGGCCGGAGGGAGTATGCATTATTTTCTTTGAAATTTTCAAACTAGCCATTCTCAAAGAGAACAATGATCATAGTAATAAAAGAAACAATTGTCATCGTTCTATTCAACCTCCCTATTTTACACCTTCACTAATGATTCTTATTTTTTTAGTGAAAATGTTCGCAATGCGCGGGGGCATAATCTAGTATGTACATGTTTGGCCATCATTATGGTCTTTAAAGAACACTAATTTCTCCAAATTATCTACACAATGCTGGATTGAAGTTTACTTTTTAAAAAATATAATTATAGGTTATATAAACTCTAGTTTCTAATTTTCTATAAACATAAATATGTTTCGTACACACTATATTAATCAAACTACATTGTTTTAAATCAATACCCAATTAAAAAATACATCTATTTCTCTTTTCCTTGGTTTAACATGGGAATTTTTCTAGTCCTAGAGCAAACACTGGTTCCTTTTATGCTTCTCCTAATAATAAGCAAATTGCCATGTTTTGCGATGGATAAAAGAAAATATATCATAATATGTCATAAAAAATATAGTTTTATCAAATATGTTAGCATCATGTGTTTTCTTATTCGAACATTAAGTATTCACTTGTTTTAACCAAATACTGGATCGCTCCATAATATTAGAAAACTATATTCACGTCAATTTGTATAAACTACAAAAAATCTGCCGCCACTAGGGCCTCAAGGAGTTTACAAATAAAAGCTAGATAAAACTATAATAA',
        'TGCTGACTAAGCCTTTTACCTTGGTTGCAGTTGTCACTTGCCATCAAGCCATGGAAGACAATAATGATGAAATTCTTGATGGGCAAAATGAAGAAGTGCAATCCCAAGTTTCTCTTCCTCAAGATATTCAGCGGATTATTATTGGTTTCCTACCCGGTAGGACTGTTCTCAAGTTCTGCAGTGTGTGCAAGTTCTGGAGAGACTGCATTGTAGAACCTGCTTTTGTGGATCACCACCTCAACTGTGCTCTCCGCTTCCGCCAGGCCATTGCCTGCTTCACCTCAGTTGATAACGGTCTTGTCCAGATGTACATGTTTGATCCCATCACAGTGAACTTCAAAAGAACAGAGCCTGTGTTCTCATCTAGGTTTCACATGTCACAACCCTGCAACGGCATGGTGTGCGCCTATGATTTAAAAGGTGCTGCTGAAGTTTTGAATCCAACAACAAGGAAGCATTTGACGCTGCCAGCTTCAGAAAGTGTATATCAGGCTCAATATTCGGAATATTTTCTTGGATATGTGCACTCTACAAAAGAGTATAAGGTAGTCGCTCTCCGCCATTGGATAAAGCACTTGACATTTGAAGTCTGCACTATTGGCACGTTGTCATGGAGGACGGTACGTGGATCTGAAGAGGAAGAACTCCTGAAGACAACAAAGCCGGTTGTTGTTAATGATGAAATGCATTGGCTACTTCTTGATGATGAATCATCTCACTTTACTCGAAAAATCCTCTCATTCAACTTGACAGATGAGAAGTTTTCATATCTTGATGTCCCAGACAGTGTAAGAGACCGTGATTTGGAATTAGTCGAGGGGGAAGGGAAACTTCATTTATGGTCTATGCCTTGTAAAGGGGCAGCATATACAGAATCAGAGATTTGGCTGGCAGACTCAACCCGGCAATTCTGGGTTCACTTGCACAATATTGCCCATCCCTCTGTTTTGGGCACGAAGCCATTTTTCATGTACAAGAGCAAGCTCTTTCTGGGGAGCCAAAAGAGATTCATCTATATTGATATTTTGGATGGGACGGTTTGCTACGTTGATATTCCTTCTGGTGAAAATATCATATCTTCTGGCATGTTTGTGGAGAGCTTTGTACCTGCTTTGACAGGCACAGGCTTGGTGAACTCAATGACATTATTAACCGGTTCTCGTTATGCTGGGTCATCATCAAGAGGCTCTGGACCATCTTCTCGTGCTGCTGGATCTTCCTCAACAAGAACTCGACGTTCACCCGCTGCCTCCAGGTGGTCCTCAGCAGTTGTGCAATCCTCCAAGCGGGCGAAGAGAACAATAAACTTAGTGTGGAAGATGTATACAGAAGGCACAAGCAAGATTCAGCAGGGGCTATGAAATAATCTCTTTGGACTGTGCAGCAGCTTGAAGCTACCTACCTACATTCCAGCAAAAGCTATTGGTCTTTGTATATGCCTATGGCAGAGAAGAAGCAGCTATTAGCAGTTTATGAGTAATGCCTATCTTGGAGAGAAAAAGGTACACCATGGAAGTGGTTTGGTAATTTGGACAGAAGATAAAGATCAGAAAAGATACAGTGATATGTTAATGTGTATTTCACATATGTTTTGCTTTGCTTAAGCCCCTGCCTATGGGGGCCTTTATACCAGAAAATGGAAAGCTATATGAAATAAACCTGTATGATTAAGGTACTCTTGTTTTGATTTGTAGTTGTAAACTGTATGCCTCCATTGCACCTGGAGCATCAGTTAATCAGTATATGTGGCAGGAAAAGATAAATACAAACATCCTTTTGTTTTTGGAAACTATATCCATACAAACTGTTGTTTAAATACATATCAGATACAAACTGTACATGATGCTTGTGGTTAATTTTGGTGTAATTTGTTTCCTTCAACTATATTAGTATATATGAGAACTGATCCTTCCATTTATGAGATATATATATATATATATATATATATATATATATATATATATATATATATATATAGACACACACACACACACAGAGAATGTTTGGGATTTTGTTGTTCAGACGGTTGGCAAGGACAGCAATGGCGGGAAGCCGAAGTATGCCCAGGCGATGTCGCCGGCGGCGCACCGCGCGCGGCAGATCATCTCCAGCTCGAAGCTCTTGACGTCGATCCTGTACAGCTCGACGTCCCTGCTCCGGTAGCTCGTCATGAACGCCGGCGTGCCATGGCTGACCTCGAGGATCAGGCTCCCGTTGGCGGCGGCGCGGATGCTGTACGGCCGGCCGTGCGCCGCCGGCCACGGCAACGGCACCGTCCGCTCCAGCCGCCACCGCGGGCCATCGCCGCCGTCGACGATGGTGTAGTAGTAGAGGCACGCCTCGCCGCCGGCGCGGTAGAAGTCGTGCGCGAACACGCCGACCTTGCCGTCTTCTCCCTCGACGACGGCGACGTGCTCCTCCCAGTAGCACGCCGGGGACGGGATCTGCTTGACGGTGATCTCCATGGCGCGCGTGTCGAGCACCAGCCACCGGTGGGTGAGGCAGTCGAGCCAGTAGAAGCAGCCGTGCGCGTAGAACCGCCGGTTCCACACGGCGTGCACCGGGCAGCCGAACGGCGAGCGGTGCCTGCTCCACACGAAGCACTCCGGCGACGGGAGCGCGCGCCACCGCCCGTCGCGCGACGCGAAGGCGAACGCCACCACCTTCCTCGGGCAACGCGCCGTCCATATCACGGCGAACGCGGGCTCTGACTCGGCGTCGGCGTCGGCGTCGGCGTCGCACGGCGCGAGGAAGGGCTCGCACCGGCGGCGGCCGCCGATGACGCCGAGCGGCCTGTCGACGGCGGCGGCGAGCTCGCGCGGGATGGGCGGGAGGACGACGTAGCGGCGGGAGAGGGGGTCGCACACGGCGAGCTCCGGGAACACGTTGTCGTCGAGGGAGGCGACGCGGTCGAGGAGGAAGCGGCCGTCGCGGTGGTCGCGGACGATCCACCCGAGGCCCCTGCGCGGGTCGTCGTCGCCCACCACCGGCGACGGCGGGAGGAACGCGAAGGAGAAGTCCGCGGCGGCCGCGACGGCGCGCGCCGCGGCGGCGGACGCGTGGGGGGGCTCGGCGGGGTGGAAGGCGCCGCCCTCGGAGGAGAACGCGAAGGAGCCCAGGAGCGCGCCGGGGCACGGCCCGTGGCGCGCGCGGTGGCGCCGGAGGAAGCGCGGCGACGACACGAGCGCGCGGAACGCGGAGCACGCCGCGGCGGCGCGCGCCAGGGAGGAGCGGGAGGGGAGGCGGACCAGGATTTCGTCCACCACGTCGTCGGGGACCTGCGTCTCGCCGGCGGCGACGATGACGGCGACGGCGCCGGCCATGGCAACAGCTGCGCGCGCGGCTGACACTCAGAGCGAGGAGGGGTGGGGGCGCGCTCGAAATATTTTATTAGAGTAAATTGTTCCGGCGGTCATTAAACTTGTAGGAGTGTGTTATCTAGGTACATAAATTCTCAAAATGCATATCCAAATCTTAGAACTTATCATGATATGTCATCTAGGTCCCAAATCCTCAAAATACATATCCAAATCTTAGAACTTATCATGATATGTCATTTAGGTCCTAAATCACCACAACTCTTTCAGAATTCTACGTGGCGTTGATGTGGCATGCCACACAGACATGACATGACATGGTATTATTTTTTCTTTTTCTTTTTTCTCTTTTTTTTCCTATTTCTTCTCCTTTCTCTGTGACCCGTGTAGAAAAAAGGAAAAAAAGAAGAATGAGAAGAAACCGAAAAAGAAAAAGAAAAGAAGAAAAAAAAGAAAAGGACACGTCACGTCCATATGGCATTGTCACATCAGCACCACATAGGATTCTAGAGGGGATATGTCAATACGTAGGATTCTAGAGGGGATGTGTCAATTTGGGACCTAGATGATATACTTTGACAAGTTATGAGATCTGGATATACGTTTTAAGAGTCTATAGACATATGACACAATCCTATAAGCTTAAGGATCGCCAATACACTTTACTCATTTTATTATCACTTCTCTCTTTTTTTTTTTGGCGCGGCAGCTGTCGTTGTCGTGTGAGACTGACCTGTGGGCCCAGCAATAGCCTCACACGTGAAAAAAAAATGAAAATCGGAATCAATTGTGAGCGAGGACCACATCATGCCGTGCGTTTGTATTTCAGCCATGGATTCAAGGACTGAATTAATGCTTTTGTTTAGGCCCTGTTTAGATCGCGTCTTAAATTTTTTCACTCCTATTAAATATAGGCTAAAAAATAACTAAATGCACAGATTACGACTAATTTACGAGACATATCTTTTAATCCTAATTGCTCCATGATTTGATAATGTGGTCCTGAAGTAAATATTTGCTAACGAGGAATTAATTAGGCTTAATAAATTCATCTCGCGGTTTACTGACAGATTCTATAATTAGTTTTTTTATTAGTGCCCGAACACCCTATGTAACATCCTATATAATACCTGATGTGGCACATCAAAATTTTACACCCCTGAATCTAAACAATCCTTAGTTGGCAGATAATCATCAGTACTTCTAAAGCTGGCAGTGAAACTAACAGACAATTGATACAAGTGGCACAGTTAAGCTTTGAGATAAAGCTAGAAATTATATAAGCAAAAAAAATCCTGAAAAACAAAGTTTTGAGCACCACATCTAGCAAATGCTAGAAGCTTCCCATCTGGCATAGTAGTACATGGTATCTTCTACCTAGGATTTGTAGAACTGAATGGAGTGATCAAGCGGAAAAAAAATCCAGAAAAAAATACATATGAAAAATATTATGATTTCTAAAATTTTAAAATAAATTAGATAATGTCTATTAAAGTCCTCTGAAATTTATGTGTTATAAATTAACTCTAAATAAATAGGACGAACAATGCATGCACCAATAGAAAAGGGAAAAAATGTACGATTATAATCACATACCCTTTATTTCATCAATTATGTTTAAAATAATAATAAATTTATTGAGGAAAAGTCTTGCATTCGAACACTTTGTCTCAAAACCAGGTCACACATTTAAATAATATATAAATCCATCGATTATTTAGTTCGTTGGTCTATTGATTTATAACGAATGATTTATCTCCCTTTGATGAAATATCAAAATTCTTTACTAAAATATCATTTTCTGACATCAATCAATAAACTCACAATAGTCTTTCTTGGACTATGAAAAAACTAAAATTCAATTAAACAACATACACTATAAATATAGGCGCGCTGATTTTCTAGTAATACCTATAACGTAATGATATATATGACACTTACAAAACTTTAGCATGTGAAGATTTTTATCGAGTGATTTGGTTTGCTACTTTATCGAAATTTTTGCATTAGCCATTTTGATAAAGCGACATCAAAATTGAATTAGCTTATTGTTGAGATTTTAGGTGGTAGGTGAAACAGTATAAATCATTGGGGTATAATTAATCGAGTATTAATTATTAAGTCTCTTTATTTTCTAATAAATGTGACCATTAAATTGTGATATAACGTGTGACCGTTCTTTTTTACTTAAAAAATTGTGTAAATATTATTTATTTTGCTGTGACATGTTTTATCATTAAATAAATTCGAAATATGACTTATACTTTAGCATATTTACATTTTTTCTAAATAAAACAAATGGTCAAACGTTATTCTATGAGTTAACGCGTTATCTATTTATAAAACGGATGTAGTATAAACTTAAAGAAAAAAACTATATAGGAAGTATTTGCACAATATGTGCCGTCTAGAATATGCGTCGTCTAGCATATATATTTAATGTCTTTGGCTCCAATATATTTTTTATTACATGATAGGCATATACACACAACACTAAACCACATATATATAACACCGATGACATATGATACTCATAGATTATATCAAGAGTGAAAACAATAATGTTAATTCCTGGATGACCGATGTTAGTTTCCGACTTTTTATCGACTGTGCCATATGAAAATGGTAGAGCATATACACATATACATATATGTGTGTATGTGTGTGTGAGTGACAAATAAACTTACTCTCTCACTAGATCCAGTTTTACAGGTCACATGAGAAGCGGAGAGGGACAGAGATTGCTTCAATAACATAAAAAAAAGGGATGGGAAGAGATGAACGCCCCGCCCAATTTTTTTAGGAAAGAGGATTCAAACATATGTTACTGCTCCCTCCGTCCTAAAATATAAGCACTTTAGCATAGTGACAAGTCAAATATTTTTAACTTTGACTATTAGTAGCAAAAAAAATTTATAATGTAAAATTGATGTTACTAGATTTATTATTAAACAAACAATCATAATATGCAACTATATTTATTTAAAACATCATATTTTTACACATATTGTTGGTCAAAGTAGCATCTCAAAAACCGTGTCAGGGTTAAAAAAAATACTTATATTTTAGATGGAGGGAGTAGCTAGTATGCTTCAATGGCATCAAGACATCTATATACTCATTCCGCCAAAATATATAATAATCTTAACCTAATATATTTATTTAGATTATTAGGTTATGTTAAATTTGGTACGGGGTTACTATATATTTTAAGATGAAGGTATTAAGCGACAGAGATCACAGCAAGTTGCATGAGGTTAGGAAAAAATTATTCGTGGTATCATTTTCTTTCGCTGTCGAACATCTCGTGTTCACGAGGACGACGCGTTTGGTAAGCACCACATGCAAGTAGACTCACGGCACAACACGACCAATGGAGTTCATTATCTTCATGAAAAAATAAACATTTATAACTTGTCCGAATGCTAGATACGCGTCAGAGGTAGAAAAGGCCATCGAATTTTGCGAAACTAAACCGGTAGAAGAGCTGCTGATTATATTTTTATAAGCAGATTAAAAACCCAGATAAGTTTTAAAAAAAGAAAAAACAACTAAACGAGAAAAATCTCGCCAAGCTCCTCAATACTACCGTTGCCGGCTAGATAAATTTACAGCACACACAACAATTCAACACTACAACACACTTATAGTAGATCATCGACGGAACCCAAACATGAGTGGTTGTTACCAAGCTTGCGCAAAAGCGACACATCAACTCCAACTTTCACAGTGAATGCATGACATCGTTGCCAAGCTTGCGAGAGCAAAGCATATCCGACTTTACCACAAACTTGTGTCGTCGTTGACGAGCTCATCACAAAAACTACCAAGCAGCTGCGACTTCCCATGACGGACATCAACCAAAGCCACCGTATCGTCGCTTCCTGCTTATGGTTGGTACCTATACACCTAGAAAGCGACTGCAACGTGTTATCGTTGCCAAGCTACATTGCACCCCAACAACAAAGCAGCTCTGACTCCCCCTAGCAAAATCAACTAAGAGCATCGGCCGCCTACTGCAAAGCAAGAAACGAATCCAAGAAGGCGAAGGCCTCGCCGAACATCCCGGCCTATTGAGTGTTGGTGTGGAAGCAGAAAGCCCGCAGCTAACGTCGATTTGACGATCAGACATATACATGAAAAGGTTCTCCAAAACTACACCCTTAACAGAAAAACGACATGAATCTCTGTTGTCGCTCGCCCGGTAACTGTGGCAAGGCTTTCGCCTGGAGCACAATGATGGAAGAAGAGGGACCATGCCATGACGATGCCTCCAAGGAGGAGAACTGTTGACGACCAAATTTGGTAAGATATGAACCAGGTTCGATATTGGAATCGAAGCGGATTCGGTAAAGAAATGGATTCGAAGAACAGAGTATGCATCGGCTGAGATGGATCGGACAGAGGACAGCCGATACAGCCGATAGAGGTGATGCAACCGATTCTGATGACGATGGTTTCGAGGATGTTTCTAGAATCGATCAAAGTGCTTCACAGGGATTGCCACGATAGAGATAAAGCTCTCAGATAGGCAAGTGTATCTATTAATTAGGATATTTCGTGTAATTTCCTTAGAGATATGTTTGGGCAAAAGTCTGCTGCAAAGACTTATGGTATCTTAGAGTTTGTTAGAGATAAGAGTCGTGTCCGGCAAGGACATGTTTTGTAATCTCGGGTATAAATAGAACCCGAACCCATATAATCAATTATCACACGATCAATACAATTTTGGCACATCGCCACCCTTTTTACTTTCGTTTTATTTCGACTAGAGGTAAACTTGTCATGGCGGCTTGCGTTCTCGGAATTAGTGCTTCCATCTTTATGACACTCTAATATTGTTTATGTAATCCGTCGAGTTATCATATATACTTT',
        'TTCAGGGACCTCCGGTACACTTTTTCCCCGGTGACAAGTTCAGGGACCTCCGGTAAAAATTAAGGAGGCCGTCATAGGCCGAAGCAGAAGACTAGCGGCCTCGAGGCCGAAATATCAAAGCAGGCCAACCGGCCCTGCAAAGTCTGAGCCCCCTGTACATTAACTCTCCCACGATCCGTCCCCGCAGCCCGCAGCGTAGGTCTCGTTTTTCTTGTCCTAATTCCCCAATCCATCTCAGGATCTCTACCGATCCATGGCGATGTCCTCCTCCTCCTTCCCCACCGCCACCGCCACCGCCACCGCCTCCTTCCCCAACTGGGTGATGCTGGAGCGATTTGTCTTCCGCAGAGACGACGACAAGTCATTCCCCGACGACACCAAGGCTACACTGAGGGCATCCGGTTCCGGATCCCACAAGACCCCCTTTACCATCGCCTTCCGTATCGCCGACCCTCCGGCGATCTCCCGCCTGTACGTGCAGTGGCCACAGGGCCCGAATCCGGAGGAGATGGTGGCATGCCACCTCGTGGCCACCCACCGCAACCTCGTTCTCGTATGCTTCTGCTACATCGTCGAGTGCCCTGTTCCGGCTTGCCCGCAGGACTACTTCATCTTCACCGCGTCCGGCGACGACCCAGTTTCCTCGCCGCTACTCAAAGCCCTCCCCCCATGTACCTACCAGCCAAAAGGGGGGGAACCCCTCCCATGTACCTACCAGCCAGAAGGCGGCTTCCCCCCATCTGATGTTGAGGGCGACGGCAACCTGCGGTATCCATTGGAGTTTCGATCCGTCGGCATCTTGTGCCAAGGCGAAGAGTTTGCCGTCGCCGAGCTGCAGGTCCTCAGAAACATCAATGCTAATGTCAAAGCCAGACTGTGCGTGCTCCGCTCGGCCATATCCTCCAAAGGTGAAGATGGAGATGGAGGCGGCCGGTGGGATATCATGGAGCTGCCAATCGTGTACGGCAGCGGCGAAGAGTACTGGGACATCTTCTACTGGACCACTGACACTGTGATCGCCTTCCAAAACTACCTCTGCTGGGTGGACTACGACCGAGGCATGCTCTTCTGCGACGTACTGCAGAAAAGGCCTGGAATCGCCTTCATCCGGTTTCCTCTGGACAGCTTCCCTAACGGTAGATCTCGCCGCCATTTCTCCCAGGTGTACCGTGGTGTGTCTGTCACACCGAGTGCGACGGCTCTGGCGCCCTCAAGTTTGCTGATGTCAACCGGCTCGATAGCAAGTTGTTAGGCTCCCTAGAACCAGGACGGGGCTATACCATCACCTGCCACACTTTGAGGACGTTAGGGCTGGATGTTGGGGCCATTGAGTGGAGCAAAGACTTTGCGATCACGTCCAAGGAGATTTGGTCCTTCAAGGGCCCTGAGCTCGTGCCTCATGAAGTTCTCCTGTTTCTTACCGTGAGCATGGAGATGCCGAATGTCATGCACTTCCTCACCTGCGACTATGAGCACGTGATCAGGAAGATGTCGGTTGTGACCATTGACCTAGCCAGCAAGACCGTGTTGTCAGTTATTCCATATGTTAATGGGCAGGAGGACCTTTCCGGTGAGGATGCCGACATGGTCAGGGCAAAGTCAAGCTATCCCCAGTCCTTCCTCCCCTCTGAGTTTTCCAAGTACTTCAATTCAATCTAACATGGTATACACATGCATCTTAATTACCTGCGTTACTACTTTCTACGGATTTCCGCCTGCTGCTGCATATTCATTTTCTTAGTTTGGTAGTAAGTCCACCTACCGGGTGCATCTGCAATTTAATTAAGCTAGTGCCTCGCTTTTGATGCTAGGTAGGGCGACGGTGGTCTAGAAATGCTGTTGGTTTTGATGGTAAAAGCGATTATGTCCTGTTGAAATGATGATTATTGAAATGATTACTCTAAGCAATTTAGGTTGTTTCTACATTGGTGGTGTCAGTGTTAGGACTAGGACGCCACTTTGATGCTCCACAAGAGAATTCCAGCCTTGTTTGGTGTCTTTGCATTGTCTACTGGAGTTAAGCATGTAGAATTGAAGTATGTCAGTTATTCTTATAGCATCAGTGCGTGGGCTAATTATAGTGGCTCTTACAAGCATACACATAGCTATATATGGTACTGCAGCCAAGCTCAATCCCTGATTCACATGCTACCCCCTTTCTTGCTAATGGATATTCAATATTCAAATTGGCTTCAATCTAAATGGAGAATAAATCAGAAGCCCTATAGACGGCACAATTCCTAGTTAAAAGTGATCACTACCATATCACTACCAGTACAAGTATTTGGAAATACTGAAGTGATCATTGGTTCACATGTTTTAATTATGTAGCTATTTCAATCTATGTATCCGCATAATTGATACATATTCATACTGCATCATAATCGTAATATCTGTTTCCTGTAGTGCTTGGTAAGCACCAACATTATCAAAATAACTCAAGATATGGGTGAATTGATTTTGTAGATTTGCATAGCGTATCCAACTCATGTTTTGTACAAATCCATTTTATCATTGATACCATAACCATCTGTGGTACTGCTCTGATCATTTCTAATTTGTATGAGAATCCGCAATATATTGCAGGAAGAGGAATAACCAGGAATGAGCATTTGTAGGAGCTAGCAGGAAGAGGAAGAACCAGGGATGAGTGTTCTGAATTAGTGGTTTACAAAGTGCTAAATGTTTACTTTCATGTATTTATTTCTTGCGTCGCTATGAACTTGAATGTCACACTTCAGAACTCCTTGTAGTGCAGTACCAACTAGAGGCATTTTGTGGATCCATTTACACCTAATATGAAAAATGGTTAAATCATCGAGCAACTGTGTTGCAAAATATATTTCTCCGTAGGTAAGCAGGGGACAAAGGATCGTTTGGCTGTTTCAAACATCGCTACTGCTCGCTGTTCAGCAGCATCAGCACGCTTTTAGGCAGCAGCTGCGTGCTTTTTTGCAAAAAAAATCATGTATGAAAGTTGTTTTAAAAAAAATCATATAATTCCATTTTACAAGTTTAAAATAATTATATATGATTCTGCTTCTTATTGATTTGAGCAAATATTATTCGAATGGGGGAGGAATGTCTACCTTAGATTCAGCTAGCCACTGCACGAAAGTGGTTTATATCCATTTTGTTTTGCAAATAGGGAGGTTGTGTGATTAGAGCTTGATCTCACATTTCTTTTGTTAGAGCAAAAGCACTACCTAATTTGTTTTGCAATTTTACCTTTGGAGATTAGCCTGGTTGGTTTTAGAGGATTAGCCATGGGGATTAGTCTCTCTTTTTGCCGGGATGACCGAAGGAGGTCACCCAATGTTATTAAGATAGAGGAGAAAGGATTAGTCTCTCTAGGTTTAGAGGATCAAATTGAGGGAATGATCCATGGGGCAACCACTACTCGATAGTGTATAAAATTTGTTCACTGATTTGTTTATTTTTGGGTAACTGTCAGAAAAAAGATTGTATTATTGTTGTTTGATTCCACACAGCATGTAGCGCGGCAAGAATACATAGTCCCTCTGCTTCTCCGTAGTCCTTGGCTCTCTTGATGATTTTTCATGCATATGTATGCTAGATCATACAGATAAAGCTAGTTCTGTATGTTTTGTTTACTTCTGAAGATGGCTTACTTTTGTTCAATTTTTAACATAATAATAAATAATCTTCAGTTTTGGTTGTTTAGCATAATAGCATTTCACTTGAATTCACTTCAGTTCAGTTTTGTTCAATGGAGATTAATAGCATTTAATTTTGTAAATTTACATGGATATATTTGTCTCTCCTACAAACACTACTTAACTAGTTTTGTCTTTGTATCTTTATATGATTATATATTTTTTTTATGATTTGCCTTCTTGCAATCTGCAATTGCTTGCACGGCTTGCATCTCATGGTTTGCAGAATATATACCCCACATTTCAGCTTCTCTAAATTTTATAGGTCCTGACATCTTCTCTGAATTTTTATCTTATATTTTTCCTTTTGTACTAATCATAATATAGAAACGAAGTTCTAAAGAATGGTCGTCAATTCTAATTTATGGCTTTTTAGGTAGTTGGTGAAGTGTACCTAGTTTTGTCAATTTTGTTAGCAATGAAGATACTAATAAGACAGTTTTGTTTGCTACCAATTGTACTTTGTTTTGTGTAAATGGACAGTACCTCCTACTGATTAACCTACTAATTATACTTAGTTTTGTGTAATTTGTTAGCAAGCCTACTAATAGTACCCTGTTTTATTAGAATGCATTGTTTGTAATTTTCTCCTTTCACTATTCTCTTTGTTTTGGTCACCAAATTTAATTGATGTAGTTATGCAACATTTTTGTGTTTTTTTTAAAGTTGCAACGAGAAGGTTGTGTGTCCCATTTGTAGTTTTGGTATTTTGCCCGATGGTTGCTTTGTAGGTTAGCTCGACGGTTGCTTGCTGGCCTAGTCATAGTCTAGCTGCAAACTTCTTGTCTTTTGAGTACTAAAAGCACACTTTTGTTCGTTTTGTGTGTAATATTTAGGAGCTGCATTATTTTATCCTTTTGTTTATTTTGCTTTGTTTTGTTTTGTAAGCTAAAAGTACTTAGTTTTGTCACCACACTGTTAGCTCATATATTCTAAAATGTTCACTAATATGTTCAACTTAATTAGTTTTGTAACCTCCTAAAATAGTTCTATTAGTTTTGTAACCTTCTAAAATATGAATTAGTTTTTGTCTGGCTGATCTTCCTTTGGTTAGGTACTACAAAGTCTTAATTCAGACATATTTCATCTATATTATTTGGTCAGGCTGGCATTTGAAGTTCTTATTTTAGTCTTATACTATAGTTTTTTTACATTTGTTAAAGATGATAATTTATTTGTTAGCACTGAGCATGTTTAGAAATCTGAAATATGAAAACATGCATGTTCTCATGAAAATAAATATTAGTTTTGTTTAAATTCCAATCCACATATTTTTTAAGCAATGTCAGAAATTACCATGCTTCACTTATTGACCTAGTGTATGTATAGTATTTGATGGATCATGTTGATTTGGATTTGCTATACTAACTTGTTCCTATTCCGGAAAAGATTTATATGTATCTTGTGTTCTAAAAATGCTATATGTGTCAGGTTGAAGGAAAATTCTAGCTACGGGGTGTCCTAATTTTGGTAGATGGTAACTAGTAATAGATAACAATTCTGTTTTATAGTGATAAGTAAATTTGACTAAATCGAGTCCAGAAAAGTGATATAATTTTCTGGAGAAGTCTTTCTTGGTGATTTGGGAAAGGGCCATTACCTATACTGATATGAAATCTGGAACTAGAAAGATCTGAACATCAATGTTCTAAAAATTTTTATCTGAATTTCTTGTGCAGAATATGAAGGAAGGTGGATCTGGAATAGATATTTACATGTCCTGTTCAGATTCCTGCAATCTGATAAACTCTTGATCTATTGTTTTCTGGATTTTTTTGGGTGTAGGGTATTAGGAAGGTGTTTGCTTTGTTACAGGGGTTGGTTGGATATTCAGAAAACCAAAATCTGAATACACTAGCACATTAGCCAGTGTTTTATTTTAGTTTATGTTATTCTGACCACAACACCAGCTGTAGCTTCAGTTTGTAGTAGAACACACTCTGATGCAAGTGGTAGGTGTACAACAGATAATTTGCCGTGAATGCTACTTAATTCAACCATTTTATTTTCCATACAGTGCTATACAAAGACACAAACATCCTTCAATTGGACGCAAATTTGTTTCAGCTTTGCTATTTTACGGTCACCTGCATCAGTCGATTTTGTTGGCAGTAGATTCTGCTTCAAGATCTGTGCGCGCAATCGGGCCTGGTAGAGGCACATTTGGTTACGGGCTGCTTCACCAGACCCGTTAACCCATGGGCCACGGATGCTCCCCTAGCATATACTCCCTCCGTTTCAAAATGTTTGACACCGTTGACTTTTTATTCATAAAATTTAAGTATATGGGCCATGGTCAAAATGTATGGGCCATGGTCAAAATGTTTGACCATTCATCTTATTCATAAAATTTAAGTAATTATTTATTCTTTTCATATAACTTGATTCATTATTAAATATACTTTTATGTACACATATAGTTTTACATATTTCATAATTTTTTTTAATAAGACGAACGGTCAAACATATGTTAAAAAGTCAACGGTGTCAAACATTTTGAAACGGAGGGAGTATTATTTTTCCCACCAACTGCCTCAGTAAATCAAGATGCTCCCCTCTCCACATTTGCTGCAGACTTCCTCCCCGTGAATCTGAGACGAACTCCGGCGACCGGCGGCGTCTACGAGCCAGCGTCACCAATTTCTCAGGTATATGAGCCGTCTCGATTATCGAAGATGCATGCGTGACTGCGTGAGGGAAACTCTGTGCCAGGGAGGCGAGCTTGGTGGCACATATCGAGTGGTAAATCGTCAGGTTACTGCTATGTTAGGAACACTAACGATTTTTCTCTTGTATTAACTGGGAACCAACGATACGCCTTGCAATCTCTCGATCCAACAGGATCAAGCTGCGCCGGCTACGCCTCCGCGTATTAGTTCATCACCGCCGTGTTTCTCGCTACTCTGTTATACGGAGTATATTATAGCAAGATCACGCAGTTTCTCTCTCTCTCTCTCTCTCGCTAGCAACATGCCAGCTGGAGCTAAGCTACTGGGCTTCACTTGGTCCATTGCTCGCCGACGAAACGTGAGTTGGGCCTTCTGGTTTTTGGGCCAAGGAATCCGGCACCCTCTTCTCAGCGCCACCATTCTTCTCTGCTTCATCAGCATCTCCTTCCATCATCTTGGCGTCGCGCTCCCGATCAGCTACCTCCGCTTCCTTGTGGATTTCTCCATCTTGTACACGGACGTCAGGCTTCTTGCTCTTGGAGTCCCTTGGCAGCATCGAGGTAGGCCTGACAAGCCCTCAATCTTGAAAACCGGCTTGCCCCCAAGCCTGTGCCTGTGGAAACCTGTAGTGTATATCCTGCATGTCCTCCCAGGTTGCGTCCTCCACTGCACCCCCTGACCAATGGGTTAGTAATTGAATAGTAGCAGAATTATGTTTTTTAGTCACTCTGTAATTAAGGAATTGCTGGGGAATCTGAAACCGAGTGAAGTCAGTCGGCAACTCAGTCTGAACCGGATGAGAAAAACCCTTGGCGCCCTTCAGTTGGGAAACATGAAATATAGGATGGATCCGAGCAGAAGCTGGTAATTGCAAGCCATAGGCCACAGTGCCAATTTTTGCAAGAACTTGAAAGGGGCCAAAATGTCGAAAGGATAACTTGTGATTAGCTCTGACGACCACTAATGACTGCACATATGGCTGTAACTTCTTTTCTTATCTGCCAAGTGTTTCATCTGCTGCTGGGCACGATTCAAGTGCTGCTGCAGAAGTTGTTGCATCAATTTCCTTTGCTGAAGCCATTGACTGACATATGGGATGGGACAATCATTCAAGCTGATGCCAAAATGACTCGGGCTGTAGCCATAGATTACTTCAAAGGGGGTTTTGCCCAAAGTAGAATGATAAGAACTGTTATATCAAAATTTTGCCAAATACAGCCAGGAGGACCATTTTGCAGGGGTGGCATGAACAGAACACTTTAAATAGATCTCAAGAAACTGGTTGACTCTCTCTATGTGGCCATCAGACTGGGGGTGATATGCTGTGCTCATATGCAATTTTGTGCCAAACCTGATGAAAAGTTGCTCCCAGAATTGGCTGGTGAAGATTTTATCTCGATCTGAAATTATTATCCTGGGTAACCCATGTAATTTGTAAACATGCTTCAAAAACTCCAGTGCAACACTGCTAGCAGTAAAAATATGTGATAATGGTATGAAGTGGGCATGTTTAGGGAACTAATCAACCACTACAAGGATGCAATTATAGTGACTGGACTTGGGCAACCCTTCAATGAAGTCTAAAGAGATGGTTTGCCAAGCACCTGTTGGAACTGGTAGTGGCTGCAAGAGGCCTGGATATTTAGCTCTGTCTGGCTTGGCTTGCAAACAGGTTTGGCAGGTCTGCAGCTTGGCCTGAATCATTTTCTTCATAGCAGTCCAAGCAAACATGCTTTTGGCTCTCCTATAAGTGACAGGAAATCCTGAATGTCCACCAATGGGGGTAGCATGCAATGCATCGATTAATTTCTCTTGCAATTCAGTATTGTCCCACCCAAATTCTCCC',
    ]

def tokenize_sequences(sequences: list[str], tokenizer_path: str) -> torch.Tensor:
    """Tokenize DNA sequences using the specified tokenizer."""
    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, trust_remote_code=True)
    
    # Assert all sequences are the same length
    sequence_lengths = [len(seq) for seq in sequences]
    assert all(length == sequence_lengths[0] for length in sequence_lengths), \
        f"All sequences must be the same length, got lengths: {sequence_lengths}"
    sequence_length = sequence_lengths[0]
    
    results = tokenizer(sequences, add_special_tokens=False, return_tensors="pt")
    assert results["input_ids"].shape == (len(sequences), sequence_length)
    return results["input_ids"]


def run_inference(model: GeneClassifier, input_ids: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
    """Run inference and aggregate logits to entities."""
    model.eval()
    with torch.inference_mode():
        # Get token-level logits
        token_logits = model(input_ids)
        B, S = input_ids.shape
        assert token_logits.shape == (B, S, model.num_labels)
        
        # Aggregate BILUO tags to entity logits
        entity_logits = model.aggregate_logits(token_logits)
        assert entity_logits.shape == (B, S, model.num_total_entities)
        
    return token_logits, entity_logits


def create_results_dataset(
    sequences: list[str], 
    token_logits: torch.Tensor, 
    entity_logits: torch.Tensor,
    config: GeneClassifierConfig,
    species_id: str
) -> xr.Dataset:
    """Convert results to Xarray dataset."""
    B, S, C = token_logits.shape
    assert B == len(sequences)
    assert C == config.num_labels

    # Create coords
    coords = {
        'sequence': np.arange(S),
        'token_class': config.token_class_names,
        'entity_class': config.token_entity_names_with_background()
    }
    
    # Create dataset
    ds = xr.Dataset(
        data_vars={
            'sequences': (['sample'], sequences),
            'token_logits': (['sample', 'sequence', 'token_class'], token_logits.cpu().numpy()),
            'entity_logits': (['sample', 'sequence', 'entity_class'], entity_logits.cpu().numpy()),
            'token_predictions': (['sample', 'sequence'], torch.argmax(token_logits, dim=-1).cpu().numpy()),
            'entity_predictions': (['sample', 'sequence'], torch.argmax(entity_logits, dim=-1).cpu().numpy()),
        },
        coords=coords,
        attrs={'species_id': species_id}
    )
    
    return ds

# ------------------------------------------------------------------------------------------------
# Visualization
# ------------------------------------------------------------------------------------------------

def visualize_results(path: str, seed: int = 42) -> str:
    # Load dataset and select 3 random samples
    ds = xr.open_zarr(path)
    rs = np.random.RandomState(seed)
    sample_indices = rs.choice(ds.sizes['sample'], size=3, replace=False)
    
    # Create subplots
    fig, axes = plt.subplots(3, 1, figsize=(15, 6), sharex=True)
    
    for i, sample_idx in enumerate(sample_indices):
        sample_data = ds.isel(sample=sample_idx)
        
        # Create discrete heatmap
        im = axes[i].imshow(sample_data.entity_logits.T, aspect='auto', cmap='viridis', interpolation='nearest')
        
        # Overlay predictions as line
        axes[i].plot(sample_data.entity_predictions, 'r-', linewidth=2, alpha=0.8)
        
        # Set labels
        axes[i].set_yticks(range(len(ds.entity_class)))
        axes[i].set_yticklabels(ds.entity_class.values)
        axes[i].set_title(f'Sample {sample_idx}')
    
    axes[-1].set_xlabel('Sequence Position')
    
    # Add colorbar
    plt.tight_layout()
    plt.subplots_adjust(right=0.85)
    cbar = plt.colorbar(im, ax=axes, label='Logit Value')
    cbar.ax.yaxis.set_label_position('left')
    fig_path = os.path.splitext(path)[0] + '.png'
    plt.savefig(fig_path, dpi=150, bbox_inches='tight')
    plt.show()
    return fig_path

# ------------------------------------------------------------------------------------------------
# CLI
# ------------------------------------------------------------------------------------------------

def main():
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    torch.set_float32_matmul_precision('high')

    parser = argparse.ArgumentParser(description='GeneClassifier inference example')
    parser.add_argument('--checkpoint', required=True, help='Path to model checkpoint')
    parser.add_argument('--tokenizer-path', required=True, help='Path to tokenizer')
    parser.add_argument('--output', required=True, help='Output path')
    parser.add_argument('--species-id', default='Athaliana', help='Species ID for the sequence')
    parser.add_argument('--device', default='cuda', help='Device to run inference on (default: cuda)')
    args = parser.parse_args()
    
    device = torch.device(args.device)
    logger.info(f"Using device: {device}")
    
    logger.info("Loading model from checkpoint...")
    model = GeneClassifier.load_from_checkpoint(args.checkpoint)
    model = model.to(device)
    
    logger.info(f"Fetching DNA sequences...")
    sequences = create_dna_sequences()
    logger.info(f"Sequence 0 preview: {sequences[0][:50]}...")
    
    logger.info("Tokenizing sequences...")
    input_ids = tokenize_sequences(sequences, args.tokenizer_path)
    input_ids = input_ids.to(device)
    logger.info(f"Input shape: {input_ids.shape}")
    
    logger.info("Running inference...")
    token_logits, entity_logits = run_inference(model, input_ids)
    logger.info(f"Token logits shape: {token_logits.shape}")
    logger.info(f"Entity logits shape: {entity_logits.shape}")
    
    logger.info("Creating Xarray dataset...")
    results = create_results_dataset(sequences, token_logits, entity_logits, model.config, args.species_id)
    logger.info(f"Dataset:\n{results}")
    
    logger.info(f"Appending results to {args.output}...")
    results.to_zarr(
        args.output,
        zarr_format=2,
        # Append to the dataset if it already exists
        **(dict(append_dim="sample") if os.path.exists(args.output) else {})
    )

    logger.info("Visualizing results...")
    fig_path = visualize_results(args.output)
    logger.info(f"Visualization saved to: {fig_path}")

    
    logger.info("Inference example complete")


if __name__ == '__main__':
    main() 